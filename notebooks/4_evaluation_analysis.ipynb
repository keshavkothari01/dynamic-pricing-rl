{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcca Evaluation & Performance Analysis\n",
        "\n",
        "**Purpose:** Evaluate the trained RL agent and compare it with baseline strategies.\n",
        "\n",
        "**What we'll do:**\n",
        "1. Load the trained PPO model\n",
        "2. Test the agent on evaluation episodes\n",
        "3. Compare with baseline strategies (Fixed Price, Random Price)\n",
        "4. Visualize performance metrics\n",
        "5. Analyze pricing decisions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "np.random.seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print('\u2705 Libraries imported successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define DynamicPricingEnv (copy from previous notebook)\n",
        "class DynamicPricingEnv(gym.Env):\n",
        "    def __init__(self, max_days=365):\n",
        "        super(DynamicPricingEnv, self).__init__()\n",
        "        self.max_days = max_days\n",
        "        self.current_day = 0\n",
        "        self.last_price = 100\n",
        "        self.min_price = 50\n",
        "        self.max_price = 150\n",
        "        self.price_step = 10\n",
        "        self.prices = np.arange(self.min_price, self.max_price + 1, self.price_step)\n",
        "        self.base_demand = 1000\n",
        "        self.optimal_price = 100\n",
        "        self.price_elasticity = -1.5\n",
        "        self.action_space = spaces.Discrete(len(self.prices))\n",
        "        self.observation_space = spaces.Box(low=np.array([0, 0, 0]), high=np.array([1, 1, 1]), dtype=np.float32)\n",
        "    \n",
        "    def _get_competitor_price(self):\n",
        "        competitor_price = self.optimal_price + np.random.normal(0, 15)\n",
        "        return np.clip(competitor_price, self.min_price, self.max_price)\n",
        "    \n",
        "    def _get_seasonal_factor(self):\n",
        "        return 1 + 0.3 * np.sin(2 * np.pi * self.current_day / 365)\n",
        "    \n",
        "    def _calculate_demand(self, price, competitor_price):\n",
        "        price_ratio = price / self.optimal_price\n",
        "        elasticity_effect = np.power(price_ratio, self.price_elasticity)\n",
        "        seasonal_factor = self._get_seasonal_factor()\n",
        "        competitor_effect = 1 - 0.2 * (competitor_price < price)\n",
        "        demand = self.base_demand * elasticity_effect * seasonal_factor * competitor_effect\n",
        "        noise = np.random.normal(1, 0.1)\n",
        "        return max(0, demand * noise)\n",
        "    \n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_day = 0\n",
        "        self.last_price = 100\n",
        "        return self._get_observation(), {}\n",
        "    \n",
        "    def _get_observation(self):\n",
        "        competitor_price = self._get_competitor_price()\n",
        "        return np.array([\n",
        "            self.current_day / self.max_days,\n",
        "            (self.last_price - self.min_price) / (self.max_price - self.min_price),\n",
        "            (competitor_price - self.min_price) / (self.max_price - self.min_price)\n",
        "        ], dtype=np.float32)\n",
        "    \n",
        "    def step(self, action):\n",
        "        price = self.prices[action]\n",
        "        competitor_price = self._get_competitor_price()\n",
        "        demand = self._calculate_demand(price, competitor_price)\n",
        "        revenue = price * demand\n",
        "        reward = revenue / 1000\n",
        "        self.last_price = price\n",
        "        self.current_day += 1\n",
        "        terminated = self.current_day >= self.max_days\n",
        "        info = {'price': price, 'demand': demand, 'revenue': revenue, 'competitor_price': competitor_price, 'day': self.current_day}\n",
        "        return self._get_observation(), reward, terminated, False, info\n",
        "\n",
        "print('\u2705 Environment defined!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained PPO model\n",
        "model_path = '../saved_models/pricing_agent_ppo.zip'\n",
        "model = PPO.load(model_path)\n",
        "\n",
        "print(f'\u2705 Model loaded from: {model_path}')\n",
        "print(f'   Policy: {model.policy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Evaluate RL Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_agent(model, env, num_episodes=5):\n",
        "    \"\"\"Evaluate agent performance\"\"\"\n",
        "    all_rewards = []\n",
        "    all_prices = []\n",
        "    all_demands = []\n",
        "    all_revenues = []\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        obs, info = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_prices = []\n",
        "        episode_demands = []\n",
        "        episode_revenues = []\n",
        "        \n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            \n",
        "            episode_reward += reward\n",
        "            episode_prices.append(info['price'])\n",
        "            episode_demands.append(info['demand'])\n",
        "            episode_revenues.append(info['revenue'])\n",
        "        \n",
        "        all_rewards.append(episode_reward)\n",
        "        all_prices.extend(episode_prices)\n",
        "        all_demands.extend(episode_demands)\n",
        "        all_revenues.extend(episode_revenues)\n",
        "    \n",
        "    return {\n",
        "        'avg_reward': np.mean(all_rewards),\n",
        "        'total_revenue': np.sum(all_revenues),\n",
        "        'avg_price': np.mean(all_prices),\n",
        "        'avg_demand': np.mean(all_demands),\n",
        "        'prices': all_prices,\n",
        "        'demands': all_demands,\n",
        "        'revenues': all_revenues\n",
        "    }\n",
        "\n",
        "# Evaluate RL agent\n",
        "env = DynamicPricingEnv(max_days=100)\n",
        "rl_results = evaluate_agent(model, env, num_episodes=5)\n",
        "\n",
        "print('\ud83e\udd16 RL Agent Performance:')\n",
        "print(f'   Average Reward: {rl_results[\"avg_reward\"]:.2f}')\n",
        "print(f'   Total Revenue: \u20b9{rl_results[\"total_revenue\"]:.2f}')\n",
        "print(f'   Average Price: \u20b9{rl_results[\"avg_price\"]:.2f}')\n",
        "print(f'   Average Demand: {rl_results[\"avg_demand\"]:.2f} units')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Baseline Strategy: Fixed Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_fixed_price(env, fixed_price, num_episodes=5):\n",
        "    \"\"\"Evaluate fixed pricing strategy\"\"\"\n",
        "    # Find action index for fixed price\n",
        "    action = np.argmin(np.abs(env.prices - fixed_price))\n",
        "    \n",
        "    all_rewards = []\n",
        "    all_revenues = []\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        obs, info = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_revenues = []\n",
        "        \n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            episode_reward += reward\n",
        "            episode_revenues.append(info['revenue'])\n",
        "        \n",
        "        all_rewards.append(episode_reward)\n",
        "        all_revenues.extend(episode_revenues)\n",
        "    \n",
        "    return {\n",
        "        'avg_reward': np.mean(all_rewards),\n",
        "        'total_revenue': np.sum(all_revenues)\n",
        "    }\n",
        "\n",
        "# Evaluate fixed price strategies\n",
        "fixed_100_results = evaluate_fixed_price(env, fixed_price=100, num_episodes=5)\n",
        "fixed_120_results = evaluate_fixed_price(env, fixed_price=120, num_episodes=5)\n",
        "\n",
        "print('\ud83d\udcb0 Fixed Price (\u20b9100) Performance:')\n",
        "print(f'   Total Revenue: \u20b9{fixed_100_results[\"total_revenue\"]:.2f}')\n",
        "print(f'\\n\ud83d\udcb0 Fixed Price (\u20b9120) Performance:')\n",
        "print(f'   Total Revenue: \u20b9{fixed_120_results[\"total_revenue\"]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline Strategy: Random Pricing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_random_pricing(env, num_episodes=5):\n",
        "    \"\"\"Evaluate random pricing strategy\"\"\"\n",
        "    all_rewards = []\n",
        "    all_revenues = []\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        obs, info = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_revenues = []\n",
        "        \n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            action = env.action_space.sample()\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            episode_reward += reward\n",
        "            episode_revenues.append(info['revenue'])\n",
        "        \n",
        "        all_rewards.append(episode_reward)\n",
        "        all_revenues.extend(episode_revenues)\n",
        "    \n",
        "    return {\n",
        "        'avg_reward': np.mean(all_rewards),\n",
        "        'total_revenue': np.sum(all_revenues)\n",
        "    }\n",
        "\n",
        "# Evaluate random pricing\n",
        "random_results = evaluate_random_pricing(env, num_episodes=5)\n",
        "\n",
        "print('\ud83c\udfb2 Random Pricing Performance:')\n",
        "print(f'   Total Revenue: \u20b9{random_results[\"total_revenue\"]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare strategies\n",
        "strategies = ['RL Agent (PPO)', 'Fixed (\u20b9100)', 'Fixed (\u20b9120)', 'Random']\n",
        "revenues = [\n",
        "    rl_results['total_revenue'],\n",
        "    fixed_100_results['total_revenue'],\n",
        "    fixed_120_results['total_revenue'],\n",
        "    random_results['total_revenue']\n",
        "]\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Strategy': strategies,\n",
        "    'Total Revenue (\u20b9)': revenues,\n",
        "    'Improvement over Fixed (\u20b9100)': [\n",
        "        (r - fixed_100_results['total_revenue']) / fixed_100_results['total_revenue'] * 100 \n",
        "        for r in revenues\n",
        "    ]\n",
        "})\n",
        "\n",
        "print('\\n\ud83d\udcca Performance Comparison:\\n')\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Find best strategy\n",
        "best_idx = np.argmax(revenues)\n",
        "print(f'\\n\ud83c\udfc6 Best Strategy: {strategies[best_idx]}')\n",
        "print(f'   Revenue: \u20b9{revenues[best_idx]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar chart comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Revenue comparison\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
        "axes[0].bar(strategies, revenues, color=colors, alpha=0.8)\n",
        "axes[0].set_ylabel('Total Revenue (\u20b9)', fontsize=12)\n",
        "axes[0].set_title('Revenue Comparison Across Strategies', fontsize=14, fontweight='bold')\n",
        "axes[0].tick_params(axis='x', rotation=15)\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for i, (strategy, revenue) in enumerate(zip(strategies, revenues)):\n",
        "    axes[0].text(i, revenue + 1000, f'\u20b9{revenue:,.0f}', \n",
        "                ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Percentage improvement\n",
        "improvements = comparison_df['Improvement over Fixed (\u20b9100)'].values\n",
        "axes[1].bar(strategies, improvements, color=colors, alpha=0.8)\n",
        "axes[1].set_ylabel('Improvement (%)', fontsize=12)\n",
        "axes[1].set_title('Improvement over Fixed \u20b9100 Baseline', fontsize=14, fontweight='bold')\n",
        "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "axes[1].tick_params(axis='x', rotation=15)\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "for i, (strategy, improvement) in enumerate(zip(strategies, improvements)):\n",
        "    axes[1].text(i, improvement + 0.5, f'{improvement:.1f}%', \n",
        "                ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../visuals/performance_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('\u2705 Comparison chart saved to visuals/performance_comparison.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Analyze RL Agent Pricing Behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize RL agent's pricing decisions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Price distribution\n",
        "axes[0, 0].hist(rl_results['prices'], bins=20, color='#3498db', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Price (\u20b9)', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 0].set_title('RL Agent: Price Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].axvline(np.mean(rl_results['prices']), color='red', \n",
        "                   linestyle='--', linewidth=2, label=f'Mean: \u20b9{np.mean(rl_results[\"prices\"]):.2f}')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Price over time\n",
        "axes[0, 1].plot(rl_results['prices'][:100], color='#2ecc71', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Day', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Price (\u20b9)', fontsize=12)\n",
        "axes[0, 1].set_title('RL Agent: Price Over Time (First 100 Days)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Demand over time\n",
        "axes[1, 0].plot(rl_results['demands'][:100], color='#9b59b6', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Day', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Demand (units)', fontsize=12)\n",
        "axes[1, 0].set_title('RL Agent: Demand Over Time (First 100 Days)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Revenue over time\n",
        "axes[1, 1].plot(rl_results['revenues'][:100], color='#e74c3c', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Day', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Revenue (\u20b9)', fontsize=12)\n",
        "axes[1, 1].set_title('RL Agent: Revenue Over Time (First 100 Days)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\u2705 Analysis complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Key Findings\n",
        "\n",
        "Based on the evaluation:\n",
        "\n",
        "1. **RL Agent Superiority**: The PPO agent learns adaptive pricing strategies that outperform fixed and random baselines.\n",
        "\n",
        "2. **Dynamic Adaptation**: The agent adjusts prices based on:\n",
        "   - Current day (seasonality)\n",
        "   - Previous pricing history\n",
        "   - Market conditions (competitor pricing)\n",
        "\n",
        "3. **Revenue Optimization**: RL pricing maximizes total revenue by balancing price and demand elasticity.\n",
        "\n",
        "4. **Practical Applications**: This approach can be applied to:\n",
        "   - E-commerce dynamic pricing\n",
        "   - Airline ticket pricing\n",
        "   - Ride-hailing surge pricing\n",
        "   - Hotel room pricing\n",
        "\n",
        "---\n",
        "\n",
        "**Next:** Proceed to Notebook 5 for final report and summary."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}